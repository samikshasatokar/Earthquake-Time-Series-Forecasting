# -*- coding: utf-8 -*-
"""Magnitude_RNN_LSTM .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U_WyVp1njwvFZukpjQ_c2SsoGhZDdMfK

Part 1 - Data Preprocessing
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import streamlit as st
import magnitude_data_cleaning
from magnitude_data_cleaning import *
from sklearn.metrics import mean_squared_error
def mag_lstm():

    #df_mag.head()

    #df_mag.describe()

    #df_mag.shape

    #df_mag['mag'].plot()

    #df_mag.mag.hist()

    #4000/4319

    dataset_train = df_mag.iloc[:4000,:]
    dataset_train.shape

    # Convert data frame / series to numpy array
    training_set = dataset_train.iloc[:, 0].values
    training_set[:5]

    """Feature Scaling"""

    #training_set.shape

    # Add extra dim for processing purpose
    training_set = training_set.reshape(-1,1)

    training_set[:5]

    #training_set.shape

    #pd.Series(training_set.flat).plot()

    """Creating a data structure with timesteps and 1 output"""

    timesteps=20 # How many lag Values to train the data
    trn_size = dataset_train.shape[0]

    X_train = []
    y_train = []
    for i in range(timesteps, trn_size):
        X_train.append(training_set[i-timesteps:i, 0])
        y_train.append(training_set[i, 0])
    X_train, y_train = np.array(X_train), np.array(y_train)

    #X_train.shape

    X_train[:1]

    y_train[:1]

    #pd.DataFrame(X_train).head()

    # Reshaping
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

    #X_train.shape

    X_train[:1]

    """Part 2 - Building the RNN / LSTM"""

    import tensorflow as tf
    from tensorflow import keras

    (X_train.shape[1],X_train.shape[2])

    """Initialising the RNN / LSTM"""

    model = keras.Sequential()

    # Adding LSTM layers
    model.add(keras.layers.LSTM(units=1,#return_sequences = True,
                                input_shape= (X_train.shape[1],X_train.shape[2]) ))
    # model.add(keras.layers.LSTM(units=70,return_sequences = True ))
    # model.add(keras.layers.LSTM(units=25 ))

    # Adding the output layer
    model.add(keras.layers.Dense(1))

    # Compiling the RNN
    model.compile(optimizer = 'adam', loss = 'mean_squared_error')

    #model.summary()

    """Fitting the RNN to the Training set"""

    history = model.fit( X_train, y_train, validation_split=0.3,epochs = 50, batch_size = 25)

    import matplotlib.pyplot as plt
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])

    """# Part 3 - Making the predictions and visualising the results"""

    dataset_test = df_mag.iloc[4000:,:]
    #dataset_test.shape

    test_set = df_mag.iloc[:, 0].values
    #test_set

    dataset_total = pd.concat((dataset_train['mag'], dataset_test['mag']), axis = 0)
    #dataset_total

    inputs = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values
    inputs = inputs.reshape(-1,1)
    #len(inputs)

    X_test = []
    for i in range(timesteps, len(inputs)):
        X_test.append(inputs[i-timesteps:i, 0])
    X_test = np.array(X_test)
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
    #X_test.shape

    #X_test.view()

    df2=pd.DataFrame(X_test[0])

    #df2.head()

    #df2.shape

    predicted_values = model.predict(X_test)
    #predicted_values

    df3=pd.DataFrame(predicted_values)

    df2=pd.concat([df2, df3], axis=1)

    #df2.head()

    #df2.isnull().sum()

    #predicted_values.shape

    #pd.Series(predicted_values.flat).plot()

    """Visualising the results"""

    # Commented out IPython magic to ensure Python compatibility.
    # %matplotlib inline

    # https://stackoverflow.com/questions/4761623/how-to-change-the-color-of-the-axis-ticks-and-labels-for-a-plot-in-matplotlib
    figure1 = plt.figure(facecolor='black', figsize=(15, 9))
    plt.plot(test_set, color='#E0BBE4', label='Real Magnitude')
    ax = plt.axes()
    ax.set_facecolor("black")
    ax.tick_params(axis='x', colors='white')
    ax.tick_params(axis='y', colors='white')
    ax.xaxis.label.set_color('white')
    ax.yaxis.label.set_color('white')
    for axis in ['top', 'bottom', 'left', 'right']:  # https://www.tutorialspoint.com/how-to-change-the-color-of-a-plot-frame-in-matplotlib
        ax.spines[axis].set_linewidth(2.5)  # change width
        ax.spines[axis].set_color('white')  # change color
    plt.title('Prediction')
    plt.xlabel('Time')
    plt.ylabel('Magnitude')
    plt.legend()
    plt.style.use('dark_background')
    st.pyplot(figure1)

    figure2 = plt.figure(facecolor='black', figsize=(10, 6))
    plt.plot(predicted_values, color = '#E0BBE4', label = 'Predicted Magnitude')
    ax = plt.axes()
    ax.set_facecolor("black")
    ax.tick_params(axis='x', colors='white')
    ax.tick_params(axis='y', colors='white')
    ax.xaxis.label.set_color('white')
    ax.yaxis.label.set_color('white')
    for axis in ['top', 'bottom', 'left', 'right']:                           #https://www.tutorialspoint.com/how-to-change-the-color-of-a-plot-frame-in-matplotlib
        ax.spines[axis].set_linewidth(2.5)  # change width
        ax.spines[axis].set_color('white')    # change color
    plt.title('Prediction')
    plt.xlabel('Time')
    plt.ylabel('Magnitude')
    plt.style.use('dark_background')
    plt.legend()
    st.pyplot(figure2)

    st.markdown('''
        The graph shown above clearly represents the plots of actual and forecasted data points. 
    ''')
    mse = round(mean_squared_error(dataset_test, df3), 2)
    st.write("Mean Squared Error = ", mse)
    st.subheader("Conclusion")
    st.write(
        "The error rate of the model is lesser which shows that the results closer to the observed values.")





