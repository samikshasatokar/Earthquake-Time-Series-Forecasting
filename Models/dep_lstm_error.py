# -*- coding: utf-8 -*-
"""depnitude_RNN_LSTM .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U_WyVp1njwvFZukpjQ_c2SsoGhZDdMfK

Part 1 - Data Preprocessing
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from depth_data_cleaning import *
from sklearn.metrics import mean_squared_error
import streamlit as st


def dep_mse_lstm():
    # df_dep.head()

    # df_dep.describe()

    # df_dep.shape

    # df_dep['dep'].plot()

    # df_dep.dep.hist()

    # 4000/4319

    dataset_train = df_dep.iloc[:4000, :]
    # dataset_train.shape

    # Convert data frame / series to numpy array
    training_set = dataset_train.iloc[:, 0].values
    # training_set[:5]

    """Feature Scaling"""

    # training_set.shape

    # Add extra dim for processing purpose
    training_set = training_set.reshape(-1, 1)

    # training_set[:5]

    # training_set.shape

    # pd.Series(training_set.flat).plot()

    """Creating a data structure with timesteps and 1 output"""

    timesteps = 20  # How many lag Values to train the data
    trn_size = dataset_train.shape[0]

    X_train = []
    y_train = []
    for i in range(timesteps, trn_size):
        X_train.append(training_set[i - timesteps:i, 0])
        y_train.append(training_set[i, 0])
    X_train, y_train = np.array(X_train), np.array(y_train)

    X_train.shape

    X_train[:1]

    y_train[:1]

    pd.DataFrame(X_train).head()

    # Reshaping
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

    X_train.shape

    X_train[:1]

    """Part 2 - Building the RNN / LSTM"""

    import tensorflow as tf
    from tensorflow import keras

    (X_train.shape[1], X_train.shape[2])

    """Initialising the RNN / LSTM"""

    model = keras.Sequential()

    # Adding LSTM layers
    model.add(keras.layers.LSTM(units=1,  # return_sequences = True,
                                input_shape=(X_train.shape[1], X_train.shape[2])))
    # model.add(keras.layers.LSTM(units=70,return_sequences = True ))
    # model.add(keras.layers.LSTM(units=25 ))

    # Adding the output layer
    model.add(keras.layers.Dense(1))

    # Compiling the RNN
    model.compile(optimizer='adam', loss='mean_squared_error')

    # model.summary()

    """Fitting the RNN to the Training set"""

    history = model.fit(X_train, y_train, validation_split=0.3, epochs=50, batch_size=25)

    import matplotlib.pyplot as plt
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])

    """# Part 3 - Making the predictions and visualising the results"""

    dataset_test = df_dep.iloc[4000:, :]
    dataset_test.shape

    test_set = df_dep.iloc[:, 0].values
    # test_set

    dataset_total = pd.concat((dataset_train['depth'], dataset_test['depth']), axis=0)
    # dataset_total

    inputs = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values
    inputs = inputs.reshape(-1, 1)
    len(inputs)

    X_test = []
    for i in range(timesteps, len(inputs)):
        X_test.append(inputs[i - timesteps:i, 0])
    X_test = np.array(X_test)
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
    X_test.shape

    # X_test.view()

    df2 = pd.DataFrame(X_test[0])

    # df2.head()

    # df2.shape

    predicted_values = model.predict(X_test)
    # predicted_values

    df3 = pd.DataFrame(predicted_values)

    df2 = pd.concat([df2, df3], axis=1)

    # f2.head()

    # df2.isnull().sum()

    predicted_values.shape

    # pd.Series(predicted_values.flat).plot()



    # X_test.shape

    dep_mse_ls = round(mean_squared_error(dataset_test, df3), 2)

    return dep_mse_ls




