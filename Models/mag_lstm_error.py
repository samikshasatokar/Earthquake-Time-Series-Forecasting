# -*- coding: utf-8 -*-
"""Magnitude_RNN_LSTM .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U_WyVp1njwvFZukpjQ_c2SsoGhZDdMfK

Part 1 - Data Preprocessing
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import streamlit as st
import magnitude_data_cleaning
from magnitude_data_cleaning import *
from sklearn.metrics import mean_squared_error
def mag_mse_lstm():

    #df_mag.head()

    #df_mag.describe()

    #df_mag.shape

    #df_mag['mag'].plot()

    #df_mag.mag.hist()

    4000/4319

    dataset_train = df_mag.iloc[:4000,:]
    dataset_train.shape

    # Convert data frame / series to numpy array
    training_set = dataset_train.iloc[:, 0].values
    training_set[:5]

    """Feature Scaling"""

    #training_set.shape

    # Add extra dim for processing purpose
    training_set = training_set.reshape(-1,1)

    training_set[:5]

    #training_set.shape

    #pd.Series(training_set.flat).plot()

    """Creating a data structure with timesteps and 1 output"""

    timesteps=20 # How many lag Values to train the data
    trn_size = dataset_train.shape[0]

    X_train = []
    y_train = []
    for i in range(timesteps, trn_size):
        X_train.append(training_set[i-timesteps:i, 0])
        y_train.append(training_set[i, 0])
    X_train, y_train = np.array(X_train), np.array(y_train)

    #X_train.shape

    X_train[:1]

    y_train[:1]

    #pd.DataFrame(X_train).head()

    # Reshaping
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

    #X_train.shape

    X_train[:1]

    """Part 2 - Building the RNN / LSTM"""

    import tensorflow as tf
    from tensorflow import keras

    (X_train.shape[1],X_train.shape[2])

    """Initialising the RNN / LSTM"""

    model = keras.Sequential()

    # Adding LSTM layers
    model.add(keras.layers.LSTM(units=1,#return_sequences = True,
                                input_shape= (X_train.shape[1],X_train.shape[2]) ))
    # model.add(keras.layers.LSTM(units=70,return_sequences = True ))
    # model.add(keras.layers.LSTM(units=25 ))

    # Adding the output layer
    model.add(keras.layers.Dense(1))

    # Compiling the RNN
    model.compile(optimizer = 'adam', loss = 'mean_squared_error')

    #model.summary()

    """Fitting the RNN to the Training set"""

    history = model.fit( X_train, y_train, validation_split=0.3,epochs = 50, batch_size = 25)

    #import matplotlib.pyplot as plt
    #plt.plot(history.history['loss'])
    #plt.plot(history.history['val_loss'])

    """# Part 3 - Making the predictions and visualising the results"""

    dataset_test = df_mag.iloc[4000:,:]
    #dataset_test.shape

    test_set = df_mag.iloc[:, 0].values
    #test_set

    dataset_total = pd.concat((dataset_train['mag'], dataset_test['mag']), axis = 0)
    #dataset_total

    inputs = dataset_total[len(dataset_total) - len(dataset_test) - timesteps:].values
    inputs = inputs.reshape(-1,1)
    #len(inputs)

    X_test = []
    for i in range(timesteps, len(inputs)):
        X_test.append(inputs[i-timesteps:i, 0])
    X_test = np.array(X_test)
    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
    #X_test.shape

    #X_test.view()

    df2=pd.DataFrame(X_test[0])

    #df2.head()

    #df2.shape

    predicted_values = model.predict(X_test)
    #predicted_values

    df3=pd.DataFrame(predicted_values)

    df2=pd.concat([df2, df3], axis=1)

    #df2.head()

    #df2.isnull().sum()

    #predicted_values.shape

    #pd.Series(predicted_values.flat).plot()

    mag_mse_ls = round(mean_squared_error(dataset_test, df3), 2)

    return mag_mse_ls







